# Quick Start Guide

## 1. Instalar DependÃªncias

```bash
# Instalar pacote em modo editable
pip install -e ".[dev]"
```

## 2. Configurar Ambiente

```bash
# Copiar .env.example para .env
cp .env.example .env

# Editar .env e adicionar sua OPENAI_API_KEY
nano .env  # ou vim .env
```

**VariÃ¡veis necessÃ¡rias no `.env`:**
```
PROVIDER=openai
OPENAI_API_KEY=sua-chave-aqui
OPENAI_CHAT_MODEL=gpt-3.5-turbo
```

## 3. Preparar ChromaDB

O sistema usa ChromaDB como banco de dados vetorial. Certifique-se de que o diretÃ³rio `chroma_db` existe:

```bash
# O diretÃ³rio chroma_db deve estar no nÃ­vel superior do projeto
ls -la ../../chroma_db
```

## 4. Popular o ChromaDB

**OpÃ§Ã£o 1: Usar script automÃ¡tico (Recomendado)**

```bash
# Popular com 10 documentos de exemplo sobre ciÃªncias espaciais
python populate_chromadb.py
```

Este script adiciona documentos sobre:
- Efeitos da microgravidade em cÃ©lulas-tronco
- AplicaÃ§Ãµes biomÃ©dicas de pesquisas espaciais
- Efeitos da radiaÃ§Ã£o em cÃ©lulas humanas
- Atrofia muscular e perda de densidade Ã³ssea
- E muito mais...

**OpÃ§Ã£o 2: Adicionar documentos manualmente**

```python
from packages.api.app.services.vector_db import VectorDBManager

db = VectorDBManager()

# Adicionar seus prÃ³prios documentos
db.add_document(
    document="Seu texto completo do artigo aqui...",
    text="https://fonte-do-artigo.com"
)
```

## 5. Iniciar API

```bash
uvicorn packages.api.app.main:app --reload --port 8000
```

Acesse http://localhost:8000/docs para ver a documentaÃ§Ã£o interativa.

## 6. Testar

```bash
# Health check
curl http://localhost:8000/health

# Fazer uma pergunta
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"question":"Quais efeitos da microgravidade em cÃ©lulas-tronco?","topK":5}'
```

**Resposta esperada:**
```json
{
  "answer": "Baseado nos documentos encontrados...",
  "sources": [],
  "article": null
}
```

## 7. Testar IntegraÃ§Ã£o

Execute o script de teste de integraÃ§Ã£o:

```bash
python test_integration.py
```

## Comandos Ãšteis

```bash
# Rodar testes
pytest

# Formatar cÃ³digo
black packages/

# Lint
ruff check packages/

# Ver logs em tempo real
tail -f logs/app.log
```

## Estrutura Simplificada

O sistema agora funciona com um fluxo simplificado **sem Redis**:

```
Pergunta â†’ VectorDBManager.query() â†’ Lista de Strings â†’ LLM â†’ Resposta
```

**Componentes:**
- âœ… **ChromaDB**: Armazena documentos e faz busca vetorial
- âœ… **VectorDBManager**: Interface simples para ChromaDB
- âœ… **Retriever**: Wrapper que usa VectorDBManager
- âœ… **Pipeline**: Orquestra retrieval + LLM
- âœ… **OpenAI/Azure**: Gera respostas baseadas no contexto

**Removidos (nÃ£o sÃ£o mais necessÃ¡rios):**
- âŒ Redis / Redis Stack
- âŒ Docker Compose
- âŒ Embeddings service separado
- âŒ TF-IDF
- âŒ Busca hÃ­brida complexa
- âŒ Re-ranking

## Troubleshooting

### ChromaDB nÃ£o encontrado
```bash
# Verifique se o diretÃ³rio existe
ls -la ../../chroma_db

# Se nÃ£o existir, serÃ¡ criado automaticamente na primeira execuÃ§Ã£o
```

### Erro "Import chromadb could not be resolved"
```bash
# Instalar ChromaDB
pip install chromadb
```

### Erro ao gerar resposta (LLM)
- Verifique se `OPENAI_API_KEY` estÃ¡ configurado no `.env`
- Teste a chave em https://platform.openai.com/api-keys
- Verifique se tem crÃ©ditos disponÃ­veis

### API nÃ£o inicia
```bash
# Verifique se porta 8000 estÃ¡ livre
lsof -i :8000

# Tente outra porta
uvicorn packages.api.app.main:app --port 8001
```

### Nenhum documento encontrado
- Verifique se o ChromaDB foi populado
- Use o script de teste para adicionar documentos de exemplo
- Confira o caminho do ChromaDB no `VectorDBManager.__init__`

### Respostas genÃ©ricas/ruins
- **Problema**: O `VectorDBManager.query()` retorna apenas metadados (`"source"`)
- **SoluÃ§Ã£o**: Modifique o mÃ©todo para retornar documentos completos:

```python
# Em packages/api/app/services/vector_db.py
def query(self, query_text: str, n_results: int = 2) -> list[str]:
    results = self.collection.query(
        query_texts=[query_text],
        n_results=n_results
    )
    
    # Retornar documentos ao invÃ©s de metadados
    documents = results.get("documents", [[]])[0]
    return documents
```

## PrÃ³ximos Passos

1. **Adicionar mais documentos** ao ChromaDB
2. **Ajustar prompts** em `packages/api/app/agent/prompts.py`
3. **Configurar LLM** (modelo, temperatura, max_tokens)
4. **Testar com diferentes perguntas**

## DocumentaÃ§Ã£o Adicional

- ðŸ“– **CHANGES.md** - Detalhes das alteraÃ§Ãµes realizadas
- ðŸ“– **ARCHITECTURE.md** - Arquitetura do sistema
- ðŸ“– **API_EXAMPLES.md** - Exemplos de uso da API
- ðŸ“– **TROUBLESHOOTING.md** - SoluÃ§Ãµes para problemas comuns
